# Configuration pour Qwen2.5 72B Instruct (abliterated) en FP8
VLLM_MODEL_ID=huihui-ai/Qwen2.5-72B-Instruct-abliterated
VLLM_CLI_ARGS=--tensor-parallel-size 2 --max-model-len 6144 --gpu-memory-utilization 0.99 --quantization fp8 --max-num-seqs 2
