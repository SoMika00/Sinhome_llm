version: "3.8"

services:
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./qdrant_storage:/qdrant/storage
    restart: on-failure

  vllm:
    build:
      context: .
      dockerfile: vllm.Dockerfile
    runtime: nvidia
    volumes:
      - /scratch/hf_cache:/root/.cache/huggingface/hub
    environment:
      NVIDIA_VISIBLE_DEVICES: "all"
    command: >
      --host 0.0.0.0
      --model ${VLLM_MODEL_ID}
      ${VLLM_CLI_ARGS}
    ports:
      - "8000:8000"
    restart: on-failure

  backend:
    build:
      context: ./backend
    depends_on:
      - vllm
      - qdrant
    ports:
      - "8001:8001"
    volumes:
      - ./backend/src:/app/src
    environment:
      VLLM_API_BASE_URL: "http://vllm:8000/v1"
      VLLM_MODEL_NAME: "${VLLM_MODEL_ID}"   # le mÃªme ID que vLLM
      QDRANT_URL: "http://qdrant:6333"      
    restart: on-failure

  frontend:
    build:
      context: ./frontend
    depends_on:
      - backend
    ports:
      - "8501:8501"
    environment:
      STREAMLIT_BACKEND_API_URL: "http://backend:8001/api/v1/chat/"
    restart: on-failure
